<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: redis | 程序人生]]></title>
  <link href="http://xiewenwei.github.com//blog/categories/redis/atom.xml" rel="self"/>
  <link href="http://xiewenwei.github.com//"/>
  <updated>2014-11-16T23:28:57+08:00</updated>
  <id>http://xiewenwei.github.com//</id>
  <author>
    <name><![CDATA[vincent]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[避免误用 Redis]]></title>
    <link href="http://xiewenwei.github.com//blog/2014/08/31/avoid-misusing-redis/"/>
    <updated>2014-08-31T23:29:00+08:00</updated>
    <id>http://xiewenwei.github.com//blog/2014/08/31/avoid-misusing-redis</id>
    <content type="html"><![CDATA[<p>Redis 是目前 NoSQL 领域的当红炸子鸡，它象一把瑞士军刀，小巧、锋利、实用，特别适合解决一些使用传统关系数据库难以解决的问题。但是 Redis 不是银弹，有很多适合它解决的问题，但是也有很多并不适合它解决的问题。另外，Redis 作为内存数据库，如果用在不适合的场合，对内存的消耗是很可观的，甚至会让系统难以承受。</p>

<p>我们可以对系统存储使用的数据以两种角度分类，一种是按数据的大小划分，分成大数据和小数据，另一种是按数据的冷热程度划分，分成冷数据和热数据，热数据是指读或写比较频繁的数据，反之则是冷数据。</p>

<p>可以举一些具体的例子来说明数据的大小和冷热属性。比如网站总的注册用户数，这明显是一个小而热的数据，小是因为这个数据只有一个值，热是因为注册用户数随时间变化很频繁。再比如，用户最新访问时间数据，这是一个量比较大，冷热不均的数据，大是数据的粒度是用户级别，每一个用户都有数据，如果有一千万用户，就意味着有一千万的数据，冷热不均是因为活跃用户的最新访问时间变化很频繁，但是可能有很大一部非活跃用户访问时间长时间不会发生变化。</p>

<p>大体而言，Redis 最适合处理的是小而热，而且是写频繁，或者读写都比较频繁的热数据。对于大而热的数据，如果其它方式很难解决问题，也可以考虑使用 Redis 解决，但是一定要非常谨慎，防止数据无限膨胀。原因如下：</p>

<p>首先，对于冷数据，无论大小，都不建议放在 Redis 中。Redis 数据要全部放在内存中，资源宝贵，把冷数据放在其中实在是一种浪费，冷数据放在普通的存储比如关系数据库中就好了。</p>

<p>其次，对于热数据，尤其是写频繁的热数据，如果量比较小，是最适合放到 Redis 中的。比如上面提到的网站总的注册用户数，就是典型的 Redis 用做计数器的例子。再比如论坛最新发表列表，最新报名列表，可以控制数量在几百到一千的规模，也是典型的 redis 做最新列表的使用方式。</p>

<p>另外，对于量比较大的热数据（或者冷热不均数据），使用 Redis 时一定要比较谨慎。这种类型数据很容易引起数据膨胀，导致 Redis 消耗内存巨大，让系统难以承受。薄荷的一个惨痛教训是把用户关注（以及被关注）数据放在 Redis 中，这是一种数据量极大，冷热很不均衡的数据，在几百万的用户级别就占用了近 10 GB左右内存，让 Redis 变得难以应付。应对这种类型的数据，可以用普通存储 + 缓存的方式。</p>

<p>如果用对了地方，比如在小而热的数据情形，Redis 表现很棒，如果用错了地方，Redis 也会带来昂贵的代价，所以使用时务必谨慎。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 使用模式之一：计数器]]></title>
    <link href="http://xiewenwei.github.com//blog/2014/07/06/redis-use-pattern-1-counter/"/>
    <updated>2014-07-06T23:23:00+08:00</updated>
    <id>http://xiewenwei.github.com//blog/2014/07/06/redis-use-pattern-1-counter</id>
    <content type="html"><![CDATA[<p>Redis 是目前 NoSQL 领域的当红炸子鸡，它象一把瑞士军刀，小巧、锋利、实用，特别适合解决一些使用传统关系数据库难以解决的问题。打算写一系列 Redis 使用模式的文章，深入总结介绍 Redis 常见的使用模式，以供大家参考。</p>

<h2>常见汇总计数器</h2>

<p>汇总计数是系统常见功能，比如网站通常需要统计注册用户数，网站总浏览次数等等。
使用 Redis 提供的基本数据类型就能实现汇总计数器，通过 <code>incr</code> 命令实现增加操作。</p>

<p>比如注册用户数，基本操作命令如下：
<code>
  # 获取注册用户数
  get total_users
  # 注册用户数增加一位
  incr total_users
</code></p>

<h2>按时间汇总的计数器</h2>

<p>通常计数还要按时间统计，比如注册用户数需要按日统计，处理方法比较简单，把日期带入计数器 key 就可以。</p>

<p>还是注册用户计数的例子，基本操作命令如下：</p>

<p><code>
  # 假定操作 2014-07-06 数据
  # 获取注册用户数
  get total_users:2014-07-06
  # 2014-07-06 注册用户数增加一位
  incr total_users:2014-07-06
  # 设置 48 小时过期时间 172800 = 48 * 60 * 60
  expire total_users:2014-07-06 172800
</code></p>

<p>为计数器设置一个 48 小时的过期时间是为了节省计数器占用空间，毕竟 redis 是内存数据库，可以在过期前执行一个任务把计数器存入关系数据库。</p>

<h2>速度控制</h2>

<p>速度控制也是 Redis 一种常见的计数用途，比如有一个 API 服务，希望控制每一个 IP 每秒请求数不超过 10 次，可以用 IP 和 时间秒作为 key 设置一个计数器，实现控制，伪代码如下所示：</p>

<p>```ruby
  # 每秒最大请求数
  MAX_REQUESTS_PER_SECOND = 10</p>

<p>  # 检查 ip 请求限制
  # @param ip
  # @raise 超过限制，抛出 RuntimeError 异常</p>

<p>  def check_request_limitation_for_ip(ip)</p>

<pre><code>time_tick = Time.now.to_i
key = "#{ip}:#{time_tick}"
num = $redis.get(key).to_i
if num &gt; MAX_REQUEST_PER_SECOND
  raise 'too many requests'
else
  $redis.incr(key)
  $redis.expire(key, 10)
end
</code></pre>

<p>  end
```</p>

<h2>使用 Hash 数据类型维护大量计数器</h2>

<p>有时候需要维护大量计数器，比如每一个论坛主题的查看数，比如每一个用户访问页面次数，因为论坛主题和用户基数可能很大，直接基于论坛主题或用户 ID 生成计数器的话，占用 Redis 资源还是相当可观的，这时可以用 Hash 数据类型压缩所需资源。</p>

<p>比如，对应论坛主题查看计数，可以由模式
<code>
  key: topic:&lt;topic_id&gt;:views
  value: view count (integer)
</code><br/>
转换为模式：
```
  key: topic:views<br/>
  value: hash</p>

<pre><code>hash key: &lt;topic_id&gt; 
hash value: view count (integer)
</code></pre>

<p>```</p>

<p>总结：利用 Redis 实现计数器，可以简单高效实现各种计数功能。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[保护 Redis 的数据]]></title>
    <link href="http://xiewenwei.github.com//blog/2014/06/16/redis-data-protection/"/>
    <updated>2014-06-16T00:08:00+08:00</updated>
    <id>http://xiewenwei.github.com//blog/2014/06/16/redis-data-protection</id>
    <content type="html"><![CDATA[<p>Redis 是非常流行的 key-value 类型的 NOSQL 数据库，它的 value 数据类型丰富多样，适合解决很多对关系数据库来说棘手的问题。Redis 是内存数据库，也就是说它把所有的数据都放在内存中。众所周知，当前机器突然断电或者系统异常崩溃时，内存的数据会丢失的，所以如果把系统的关键数据放在 Redis 中必须做好保护措施。</p>

<p>Redis 提供了两种持久化数据机制：</p>

<p>一种是 RDB 机制。这种方式是把当前整个 Redis 内存数据快照写到磁盘上。优点是比较简单，恢复快速。缺点是代价比较昂贵，尤其当数据量很大时，会严重影响到 Redis（照成 Redis 停顿），而且会极度消耗磁盘 IO。</p>

<p>另一种是 AppendOnly 机制。这种方式类似于 log，把数据操作命令全部存入 log 文件。优点是每段时间写入数据不是很大，可以设置很短的写入时间间隔（比如1秒钟）。缺点是 log 文件可能会远大于数据文件，通常会是数据文件大小的 3~5 倍，而且恢复的时间要远大于 RDB 方式的恢复时间。</p>

<p>这两种机制各有优劣，不过它们是可以结合起来使用的。在实际使用过程，通常还结合 Redis 的 slave 功能，做到对 Redis 影响更小，保护更充分。具体的做法是对 Redis 建立 master 和 slave，在 master 上根本不使用任何持久化机制，只在 slave 上建立结合 RDB 和 AppendOnly 的持久化机制。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分割 Redis 实例]]></title>
    <link href="http://xiewenwei.github.com//blog/2014/06/08/sharding-redis-instance/"/>
    <updated>2014-06-08T23:59:00+08:00</updated>
    <id>http://xiewenwei.github.com//blog/2014/06/08/sharding-redis-instance</id>
    <content type="html"><![CDATA[<p>薄荷 App 上的伙伴功能大量使用了内存数据库 Redis，随着数据量的快速增长，Redis 膨胀得很快，已经接近 12 GB规模，这些数据全部放在单个 Redis 实例中。单个巨大 Redis 实例有如下几个坏处：</p>

<ol>
<li><p>首先，需要一台内存很大的机器。Redis 是内存数据库，它需要把所有需求全部放在内存中，需要为之装下 12 GB的 Redis 实例，至少需要 12 GB 内存大小的机器，考虑的预留增长空间，一般需要 12 * 1.5 约 18 GB 内存。 另外还有一个考虑的因素是，Redis 进行硬盘数据存储时，fork 进程需要消耗同样大小的内存，因此一个 12GB 的 redis 实例需要 32 GB左右的内存比较合适，这对机器提出了很高的要求，常常难以满足。</p></li>
<li><p>然后，Redis 容易成为性能瓶颈。Redis 的并发模型是单进程单线程，它不能充分利用多核 CPU，在请求数很高，或者某一些请求处理比较慢时（比如一些大的数据排序），可能会成为系统的性能瓶颈。有方法可以缓解甚至这个问题，就是建立多个 Redis 实例，通过多个 Redis 连接来实现。</p></li>
<li><p>另外，单个巨大的 Redis 实例也会增加数据管理难度，因为这么大的数据量，无论是复制，备份操作都比较慢，容易对线上系统造成冲击。</p></li>
</ol>


<p>因此，十分有必要把单个巨大的 Redis 实例分割成多个小的 Redis 实例。</p>

<p>使用 Redis 的复制机制，可以在线平滑处理 Redis 实例分割，几乎不会对系统有很大的影响。</p>

<p>分割的具体操作思路如下：</p>

<ol>
<li><p>首先，规划 Redis 分割策略，通常是基于业务划分，比如薄荷伙伴是基于业务分成 timeline, user_relationship, other 3个 Redis 实例。规划好之后，需要根据规划结果对应用程序中 Redis 程序代码做修改，通常是有一个统一的 Redis 链接修改为多个 Redis 连接，不同业务使用不同的连接。</p></li>
<li><p>然后，通过 Redis 复制功能建立多个 Redis 副本，让不同 Redis 连接使用不同的 Redis 副本，在 Redis 副本中删除多余的数据。批量删除某个模式的 keys，可以使用下面的 shell 命令：
<code>
redis-cli KEYS "&lt;pattern&gt;" | xargs redis-cli DEL
</code>
<pattern> 改成实际的模式，如
<code>
redis-cli KEYS "user:*:followers" | xargs redis-cli DEL
</code>
表示删除 user followers 数据。</p></li>
<li><p>最后通过来回切换并重启 Redis 实例达到完全分割 Redis 实例。</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
